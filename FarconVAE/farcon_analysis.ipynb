{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read trained FarconVAE models for each dataset and attribute and evalutae performance\n",
    "This file allows you to read and analyze the train FarconVAE models from the paper. Newly trained models using the code in this repo will be included as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from model.farcon import *\n",
    "from collections import namedtuple\n",
    "from train.train_farcon import *\n",
    "from model.farcon import *\n",
    "from eval import *\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "eval_model = 'lr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return model args for data\n",
    "def get_args(data_name):\n",
    "    args = namedtuple('args', ['data_name', 'y_dim', 's_dim', 'n_features', 'latent_dim', 'hidden_units', 'sensitive', 'target', 'train_file_name', 'test_file_name', 'encoder', 'batch_size', \n",
    "                               'batch_size_te', 'epochs', 'fade_in', 'beta_anneal', 'clf_act', 'clf_seq', 'clf_hidden_units', 'connection', 'enc_act', 'dec_act', 'enc_seq', 'dec_seq', 'pred_act', 'pred_seq',\n",
    "                                 'model_path', 'data_path', 'result_path', 'clf_path', 'patience', 'kernel', 'drop_p', 'neg_slop', 'clf_layers', 'cont_xs', 'env_flag', 'tr_ratio', 'last_epmod_eval'])\n",
    "    args.data_name = data_name\n",
    "    # Defaults\n",
    "    args.kernel = 'g'\n",
    "    args.drop_p = 0.3\n",
    "    args.neg_slop = 0.1\n",
    "    args.clf_layers = 2\n",
    "    args.cont_xs = 1\n",
    "    args.env_flag = 'nn'\n",
    "    args.tr_ratio = 1.0\n",
    "    args.last_epmod_eval = 1\n",
    "\n",
    "    # Per dataset\n",
    "    if args.data_name == 'adult':\n",
    "        args.y_dim = 1\n",
    "        args.s_dim = 1\n",
    "        args.n_features = 95\n",
    "        args.latent_dim = 15\n",
    "        args.hidden_units = 64\n",
    "        args.sensitive = 'gender_ Male'\n",
    "        args.target = 'income_ >50K'\n",
    "        args.train_file_name = 'adult_train_bin.csv'\n",
    "        args.test_file_name = 'adult_test_bin.csv'\n",
    "        args.encoder = 'mlp'\n",
    "        args.batch_size = 30162\n",
    "        args.batch_size_te = 15060\n",
    "        args.epochs = 300\n",
    "        args.fade_in = 1\n",
    "        args.beta_anneal = 0\n",
    "        args.clf_act = 'leaky'\n",
    "        args.clf_seq = 'fad'\n",
    "        args.clf_hidden_units = 64\n",
    "        args.connection = 0\n",
    "        args.enc_act = 'gelu'\n",
    "        args.dec_act = 'gelu'\n",
    "        args.enc_seq = 'fa'\n",
    "        args.dec_seq = 'fa'\n",
    "        args.pred_act = 'leaky'\n",
    "        args.pred_seq = 'fba' if args.kernel == 't' else 'fad'\n",
    "        args.model_path = './model_adult'\n",
    "        args.data_path = './data/adult/'\n",
    "        args.result_path = './result_adult'\n",
    "        args.clf_path = './bestclf/bestclf_adult.pth'\n",
    "    elif args.data_name == 'german':\n",
    "        args.y_dim = 1\n",
    "        args.s_dim = 1\n",
    "        args.n_features = 45\n",
    "        args.latent_dim = 5\n",
    "        args.hidden_units = 64\n",
    "        args.sensitive = 'gender_ Male'\n",
    "        args.target = 'risk_Bad'\n",
    "        args.train_file_name = 'german_train_bin.csv'\n",
    "        args.test_file_name = 'german_test_bin.csv'\n",
    "        args.encoder = 'mlp'\n",
    "        args.batch_size = 800\n",
    "        args.batch_size_te = 200\n",
    "        args.epochs = 2000\n",
    "        args.fade_in = 0\n",
    "        args.beta_anneal = 1\n",
    "        args.clf_act = 'leaky'\n",
    "        args.clf_seq = 'fbad'\n",
    "        args.clf_hidden_units = 64\n",
    "        args.connection = 0\n",
    "        args.enc_act = 'prelu'\n",
    "        args.dec_act = 'prelu'\n",
    "        args.enc_seq = 'fa'\n",
    "        args.dec_seq = 'fa'\n",
    "        args.pred_act = 'leaky'\n",
    "        args.pred_seq = 'fba'\n",
    "        args.model_path = './model_german'\n",
    "        args.data_path = './data/german/'\n",
    "        args.result_path = './result_german'\n",
    "        args.clf_path = './bestclf/bestclf_german.pth'\n",
    "\n",
    "    # Add adult for age as sensitive\n",
    "      # Add adult for age as sensitive\n",
    "    elif args.data_name == 'adult_age':\n",
    "        args.y_dim = 1\n",
    "        args.s_dim = 1\n",
    "        args.n_features = 95\n",
    "        args.latent_dim = 15\n",
    "        args.hidden_units = 64\n",
    "        args.sensitive = 'age'\n",
    "        args.target = 'income_ >50K'\n",
    "        args.train_file_name = 'adult_train_bin.csv'\n",
    "        args.test_file_name = 'adult_test_bin.csv'\n",
    "        args.encoder = 'mlp'\n",
    "        args.batch_size = 30162\n",
    "        args.batch_size_te = 15060\n",
    "        args.epochs = 300\n",
    "        args.fade_in = 1\n",
    "        args.beta_anneal = 0\n",
    "        args.clf_act = 'leaky'\n",
    "        args.clf_seq = 'fad'\n",
    "        args.clf_hidden_units = 64\n",
    "        args.connection = 0\n",
    "        args.enc_act = 'gelu'\n",
    "        args.dec_act = 'gelu'\n",
    "        args.enc_seq = 'fa'\n",
    "        args.dec_seq = 'fa'\n",
    "        args.pred_act = 'leaky'\n",
    "        args.pred_seq = 'fba' if args.kernel == 't' else 'fad'\n",
    "        args.model_path = './model_adult_age_no_clf'\n",
    "        args.data_path = './data/adult/'\n",
    "        args.result_path = './result_adult_age_no_clf'\n",
    "        args.clf_path = 'no' #'./bestclf/bestclf_adult.pth'\n",
    "    # Add SCF, Race\n",
    "    elif args.data_name == 'SCF_Race':\n",
    "        args.y_dim = 1\n",
    "        args.s_dim = 1\n",
    "        args.n_features = 3531 #******\n",
    "        args.latent_dim = 120 # Increase\n",
    "        args.hidden_units = 120\n",
    "        args.sensitive = 'x6809' # sensitive race\n",
    "        args.target = 'x3004' # target loan\n",
    "        args.train_file_name = 'SCF_train.csv'\n",
    "        args.test_file_name = 'SCF_test.csv'\n",
    "        args.encoder = 'mlp'\n",
    "        args.batch_size = 30162\n",
    "        args.batch_size_te = 15060\n",
    "        args.epochs = 300\n",
    "        args.fade_in = 1\n",
    "        args.beta_anneal = 0\n",
    "        args.clf_act = 'leaky'\n",
    "        args.clf_seq = 'fad'\n",
    "        args.clf_hidden_units = 64\n",
    "        args.connection = 0\n",
    "        args.enc_act = 'gelu'\n",
    "        args.dec_act = 'gelu'\n",
    "        args.enc_seq = 'fa'\n",
    "        args.dec_seq = 'fa'\n",
    "        args.pred_act = 'leaky'\n",
    "        args.pred_seq = 'fba' if args.kernel == 't' else 'fad'\n",
    "        args.model_path = './model_scf' #'./model_adult'\n",
    "        args.data_path = './data/scf/'\n",
    "        args.result_path = './result_scf_race'\n",
    "        args.clf_path = 'no' #'./bestclf/bestclf_adult.pth'\n",
    "    elif args.data_name == 'SCF_Siblings':\n",
    "        args.y_dim = 1\n",
    "        args.s_dim = 1\n",
    "        args.n_features = 3529 #******\n",
    "        args.latent_dim = 120 # Increase\n",
    "        args.hidden_units = 120\n",
    "        args.sensitive = 'x6809' # sensitive race\n",
    "        args.target = 'x3004' # target loan\n",
    "        args.train_file_name = 'SCF_Siblings_train.csv'\n",
    "        args.test_file_name = 'SCF_Siblings_test.csv'\n",
    "        args.encoder = 'mlp'\n",
    "        args.batch_size = 30162\n",
    "        args.batch_size_te = 15060\n",
    "        args.epochs = 300\n",
    "        args.fade_in = 1\n",
    "        args.beta_anneal = 0\n",
    "        args.clf_act = 'leaky'\n",
    "        args.clf_seq = 'fad'\n",
    "        args.clf_hidden_units = 64\n",
    "        args.connection = 0\n",
    "        args.enc_act = 'gelu'\n",
    "        args.dec_act = 'gelu'\n",
    "        args.enc_seq = 'fa'\n",
    "        args.dec_seq = 'fa'\n",
    "        args.pred_act = 'leaky'\n",
    "        args.pred_seq = 'fba' if args.kernel == 't' else 'fad'\n",
    "        args.model_path = './model_scf_siblings' #'./model_adult'\n",
    "        args.data_path = './data/scf/'\n",
    "        args.result_path = './result_scf_siblings'\n",
    "        args.clf_path = 'no' #'./bestclf/bestclf_adult.pth'\n",
    "    \n",
    "    args.patience = int(args.epochs * 0.10)\n",
    "    return args\n",
    "    # -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data attributes\n",
    "data_attributes = {'SCF_Siblings': {'data_name': 'SCF', 'sensitive': '# Siblings', 's=0': 'Few (<4)', 's=1': 'Many (4+)', 's=0 parity':0.13523065476190477 , 's=1 parity': 0.21307072515666964, 's=0 proportion': 0.8783356932795992, 's=1 proportion': 0.12166430672040082},\n",
    "                   'SCF_Race': {'data_name': 'SCF', 'sensitive': 'Race', 's=0': 'White', 's=1': 'Black', 's=0 parity': 0.12142170989433237, 's=1 parity': 0.27702948671277755, 's=0 proportion': 0.8503975601786298, 's=1 proportion':0.14960243982137023},\n",
    "                     'adult': {'data_name': 'Adult', 'sensitive': 'Sex', 's=0': 'Female', 's=1': 'Male', 's=0 parity':  0.11357604627424293, 's=1 parity': 0.31247747895305794, 's=0 proportion': 0.32495245676882933, 's=1 proportion': 0.6750475432311707},\n",
    "                     'adult_age': {'data_name': 'Adult', 'sensitive': 'Age', 's=0': 'Young', 's=1': 'Old', 's=0 parity': 0.1421809180527207, 's=1 parity': 0.3574678981752647, 's=0 proportion':  0.4908009375967449, 's=1 proportion': 0.5091990624032551}\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_predict(predictor, test_dl, target, device):\n",
    "    predictor.eval()\n",
    "    N_test, correct_cnt = 0, 0\n",
    "    y_pred_raw = torch.tensor([], device=device)\n",
    "    s_pred_raw = torch.tensor([], device=device)\n",
    "    with torch.no_grad():\n",
    "        for feature, s, y in test_dl:\n",
    "            feature, s, y = feature.to(device), s.to(device), y.to(device)\n",
    "            prediction_logit = predictor(feature)\n",
    "\n",
    "            # get accuracy\n",
    "            N_test += feature.size(0)\n",
    "            if target == 'y':\n",
    "                correct_cnt += ((prediction_logit > 0) == y).sum().item()\n",
    "                y_pred_raw = torch.cat((y_pred_raw, prediction_logit))\n",
    "            else:\n",
    "                correct_cnt += ((prediction_logit > 0) == s).sum().item()\n",
    "                s_pred_raw = torch.cat((s_pred_raw, prediction_logit))\n",
    "\n",
    "    if target == 'y':\n",
    "        mask = y_pred_raw < 0\n",
    "        y_pred = torch.ones_like(y_pred_raw)\n",
    "        y_pred[mask] = 0\n",
    "        return (y_pred.cpu()).reshape(-1, 1), correct_cnt / N_test  # y pred, y acc\n",
    "    else:\n",
    "        mask = s_pred_raw < 0\n",
    "        s_pred = torch.ones_like(s_pred_raw)\n",
    "        s_pred[mask] = 0\n",
    "        return (s_pred.cpu()).reshape(-1, 1),correct_cnt / N_test  # s acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of files in foler that start with the prefix\n",
    "def get_files_starting_with(folder_path, prefix):\n",
    "    files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.startswith(prefix):\n",
    "            files.append(os.path.join(folder_path, file))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the trained farcon models, and s and y classifiers for their downstream representations\n",
    "def get_models(args):\n",
    "    data_name = args.data_name\n",
    "    models = {}\n",
    "\n",
    "\n",
    "    ids_to_del = []\n",
    "\n",
    "\n",
    "    model_path = args.model_path #'/model_adult'\n",
    "    file_start = 'farcon_'\n",
    "    file_names = get_files_starting_with(model_path, file_start)\n",
    "\n",
    "    # For each file (vfae model) in the folder, get new representation of test data\n",
    "    for file in file_names:\n",
    "        # get id from file name (part of string after the prefix)\n",
    "        id = file[len(model_path) + len(file_start):]\n",
    "        id = id[:id.index('.pth')]\n",
    "        # Get model from file\n",
    "        model = FarconVAE(args, None)\n",
    "        state_dict = torch.load(file)\n",
    "        try:\n",
    "            model.load_state_dict(state_dict)\n",
    "            # Add model to id in dictionary\n",
    "            models[id] = {'farcon':model}\n",
    "            #print('farocn loaded')\n",
    "        except:\n",
    "            print(\"Error loading farcon model\")\n",
    "            #ids_to_del.append(id)\n",
    "            continue\n",
    "\n",
    "        # Get clf model\n",
    "        clf_xy = BestClf(args.n_features, args.y_dim, args.clf_hidden_units, args)\n",
    "        # If has saved best clf, use that one\n",
    "        if args.clf_path != 'no': # Is this applying to adult_age?\n",
    "            clf_xy.load_state_dict(torch.load(args.clf_path, map_location=device))\n",
    "        # Otherwise take from same folder as farcon model\n",
    "        else:\n",
    "            clf_file= model_path + '/clf' + id + '.pth'\n",
    "            clf_xy.load_state_dict(torch.load(clf_file, map_location=device))\n",
    "        models[id]['clf'] = clf_xy\n",
    "\n",
    "    # Get s classifying models\n",
    "        \n",
    "\n",
    "    \n",
    "    downstream_prefix_s = data_name + '_downstream_s'\n",
    "    downstream_prefix_y = data_name + '_downstream_y'\n",
    "    result_model_path = args.result_path#result_path #'/result_adult'\n",
    "    \n",
    "    for id in models.keys():\n",
    "        s_file = result_model_path+'/'+ downstream_prefix_s + id + '.pth.pt' \n",
    "        y_file = result_model_path+'/'+ downstream_prefix_y + id + '.pth.pt'\n",
    "        # if s or y file not found, delete dictionary entry\n",
    "        if not os.path.isfile(s_file) or not os.path.isfile(y_file):\n",
    "            ids_to_del.append(id)\n",
    "            print('missing file for id:', id)\n",
    "            continue\n",
    "        args.pred_seq = 'fad' #*********\n",
    "\n",
    "        clf_y = OneLinearLayer(args.latent_dim, args.y_dim) if eval_model == \"lr\" else Predictor(args.latent_dim, args.y_dim, args.hidden_units, args)\n",
    "        clf_s = Predictor(args.latent_dim, args.s_dim, args.hidden_units, args=args)\n",
    "       \n",
    "        try:\n",
    "            #print(torch.load(s_file).keys())\n",
    "            clf_s.load_state_dict(torch.load(s_file))\n",
    "        except:\n",
    "            try:\n",
    "                # Try with new structure\n",
    "                args.pred_seq = 'fba'\n",
    "                clf_s = Predictor(args.latent_dim, args.s_dim, args.hidden_units, args=args)\n",
    "                clf_s.load_state_dict(torch.load(s_file))\n",
    "                args.pred_seq = 'fad'\n",
    "            except:\n",
    "                # If still fails, delete id\n",
    "                print(\"Error loading s model\")\n",
    "                print(\"Suggested keys: \",torch.load(s_file).keys())\n",
    "                ids_to_del.append(id)\n",
    "                continue\n",
    "        try:\n",
    "            clf_y.load_state_dict(torch.load(y_file))\n",
    "        except:\n",
    "            print(\"Error loading y model\")\n",
    "            ids_to_del.append(id)\n",
    "            continue\n",
    "        models[id]['s'] = clf_s\n",
    "        models[id]['y'] = clf_y\n",
    "    print('ids to delete:', ids_to_del)\n",
    "    for id in list(set(ids_to_del)):\n",
    "        del models[id]\n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latent space representation for each model. Take models dict and data as argument\n",
    "def get_latent_representations(models: dict, args):\n",
    "    train_loader, test_loader = get_xsy_loaders(os.path.join(args.data_path, args.train_file_name),\n",
    "                                                    os.path.join(args.data_path, args.test_file_name),\n",
    "                                                    args.data_name, args.sensitive, args.batch_size_te, args) # Can do this way or by uncommenting prior lines i think\n",
    "    farcon_model = models['farcon']\n",
    "    clf_model = models['clf']\n",
    "    test_representation, _, _, _ = encode_all(args, test_loader.dataset, farcon_model,clf_model, device=device, is_train=False) #(from eval.py)\n",
    "    train_representation, _, _, _ = encode_all(args, train_loader.dataset, farcon_model,clf_model, device=device, is_train=True)\n",
    "    return train_representation, test_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return y and s predictions for latent representation of test data\n",
    "def get_preds(cur_models, latent_representation, train_loader, test_loader, args):\n",
    "    _, te_dl = get_representation_loader(latent_representation, latent_representation, train_loader.dataset, test_loader.dataset, args.batch_size_te)\n",
    "    y_model = cur_models['y']\n",
    "    s_model = cur_models['s']\n",
    "    #s_preds[id], y_preds[id] = get_preds(cur_models, latent_representations)\n",
    "    y_pred, y_acc = evaluator_predict(y_model, te_dl, 'y', device)\n",
    "    s_pred, s_acc = evaluator_predict(s_model, te_dl, 's', device)\n",
    "    return y_pred, y_acc,s_pred, s_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get models for Adult, Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_by_experiment(data_name):\n",
    "    accuracies = {}\n",
    "    args = get_args(data_name = data_name)\n",
    "    models = get_models(args)\n",
    "    #print('models:', models)\n",
    "    train_loader, test_loader = get_xsy_loaders(os.path.join(args.data_path, args.train_file_name),\n",
    "                                                    os.path.join(args.data_path, args.test_file_name),\n",
    "                                                    args.data_name, args.sensitive, args.batch_size_te, args) # Can do this way or by uncommenting prior lines i think\n",
    "    for id in models.keys():\n",
    "        print(id)\n",
    "        accuracies[id] = {'y_acc': [], 's_acc': [], 'y_pred': [], 'y_true': [], 's_pred': [], 's_true': []} # Fill with results of predictor\n",
    "        cur_models = models[id]\n",
    "        train_rep, test_rep = get_latent_representations(cur_models, args)\n",
    "        y_pred, y_acc,s_pred, s_acc = get_preds(cur_models, test_rep, train_loader, test_loader, args)\n",
    "        \n",
    "        #print(y_acc, s_acc)\n",
    "        # This is wrong **** replaces each time\n",
    "        accuracies[id]['y_acc'].append(y_acc)\n",
    "        accuracies[id]['s_acc'].append(s_acc)\n",
    "        accuracies[id]['y_pred'].append(y_pred)\n",
    "        accuracies[id]['s_pred'].append(s_pred)\n",
    "        accuracies[id]['y_true'].append(test_loader.dataset.y)\n",
    "        accuracies[id]['s_true'].append(test_loader.dataset.s)\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def get_s_baselines_by_experiment(data_name):\n",
    "    args = get_args(data_name = data_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter accuracies into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing file for id: _2024_03_05_17_30_18_369778_ours\n",
      "ids to delete: ['_2024_03_05_17_30_18_369778_ours']\n",
      "_2024_03_06_01_40_56_403815_ours\n",
      "_2024_03_05_22_46_11_320915_ours\n",
      "_2024_03_05_22_09_40_994430_ours\n",
      "_2024_03_05_17_58_04_316124_ours\n",
      "_2024_03_05_20_10_17_982934_ours\n",
      "_2024_03_05_19_14_29_896811_ours\n",
      "_2024_03_05_19_39_34_253995_ours\n",
      "_2024_03_05_21_06_17_486998_ours\n",
      "_2024_03_05_23_45_55_384556_ours\n",
      "_2024_03_05_18_49_10_855960_ours\n",
      "_2024_03_06_03_49_40_369269_ours\n",
      "_2024_03_05_18_23_49_638763_ours\n",
      "_2024_03_05_20_39_06_565216_ours\n",
      "_2024_03_06_03_14_38_296293_ours\n",
      "_2024_03_06_02_14_03_781213_ours\n",
      "_2024_03_05_17_32_16_991758_ours\n",
      "_2024_03_06_01_05_07_432427_ours\n",
      "_2024_03_06_02_47_18_326329_ours\n",
      "_2024_03_06_04_21_00_427210_ours\n",
      "_2024_03_05_23_14_43_338087_ours\n",
      "ids to delete: []\n",
      "_2024_03_19_14_11_57_463850_ours\n",
      "_2024_03_19_16_17_03_961684_ours\n",
      "_2024_03_19_06_03_38_440582_ours\n",
      "_2024_03_19_12_02_17_222115_ours\n",
      "_2024_03_18_14_44_59_266007_ours\n",
      "_2024_03_19_18_07_12_463912_ours\n",
      "_2024_03_19_15_14_02_367853_ours\n",
      "_2024_03_19_12_50_14_696546_ours\n",
      "_2024_03_19_14_40_16_563703_ours\n",
      "_2024_03_19_23_54_37_282640_ours\n",
      "_2024_03_18_16_49_50_408904_ours\n",
      "_2024_03_19_10_36_52_578254_ours\n",
      "_2024_03_19_16_58_38_370626_ours\n",
      "_2024_03_18_17_30_25_096393_ours\n",
      "_2024_03_19_10_10_18_921056_ours\n",
      "_2024_03_19_20_41_16_952888_ours\n",
      "_2024_03_19_13_44_40_683297_ours\n",
      "_2024_03_19_11_18_16_922318_ours\n",
      "_2024_03_19_13_16_16_556319_ours\n",
      "_2024_03_19_15_45_05_750365_ours\n",
      "Error loading farcon model\n",
      "Error loading farcon model\n",
      "missing file for id: _2024_03_18_13_02_57_422262_ours\n",
      "ids to delete: ['_2024_03_18_13_02_57_422262_ours']\n",
      "_2024_03_11_16_52_38_142393_ours\n",
      "_2024_03_14_04_05_41_798168_ours\n",
      "_2024_03_16_12_13_18_647426_ours\n",
      "_2024_03_12_09_10_07_234428_ours\n",
      "_2024_03_14_10_48_09_800939_ours\n",
      "_2024_03_14_17_51_05_762280_ours\n",
      "_2024_03_12_17_04_59_712519_ours\n",
      "_2024_03_17_13_45_10_431062_ours\n",
      "_2024_03_12_02_39_57_039507_ours\n",
      "_2024_03_13_15_30_47_692270_ours\n",
      "Error loading farcon model\n",
      "Error loading farcon model\n",
      "Error loading farcon model\n",
      "Error loading farcon model\n",
      "Error loading farcon model\n",
      "missing file for id: _2024_03_19_16_10_05_704771_ours\n",
      "missing file for id: _2024_03_19_15_53_03_478512_ours\n",
      "missing file for id: _2024_03_20_10_52_42_885282_ours\n",
      "missing file for id: _2024_03_19_15_17_49_486374_ours\n",
      "ids to delete: ['_2024_03_19_16_10_05_704771_ours', '_2024_03_19_15_53_03_478512_ours', '_2024_03_20_10_52_42_885282_ours', '_2024_03_19_15_17_49_486374_ours']\n",
      "_2024_03_20_04_09_02_783126_ours\n",
      "_2024_03_19_16_16_13_480385_ours\n"
     ]
    }
   ],
   "source": [
    "#accuracies = {'Adult_Sex':{}, 'Adult_Age': {}, 'SCF_Race': {}}\n",
    "accuracies = {}\n",
    "# Get accuracies adult sex\n",
    "data_name = 'adult'\n",
    "results = get_accuracies_by_experiment(data_name=data_name)\n",
    "accuracies[data_name] = results\n",
    "\n",
    "data_name = 'adult_age'\n",
    "results = get_accuracies_by_experiment(data_name=data_name)\n",
    "accuracies[data_name] = results\n",
    "\n",
    "data_name = 'SCF_Race'\n",
    "results = get_accuracies_by_experiment(data_name=data_name)\n",
    "accuracies[data_name] = results\n",
    "\n",
    "\n",
    "data_name = 'SCF_Siblings'\n",
    "results = get_accuracies_by_experiment(data_name=data_name)\n",
    "accuracies[data_name] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_metrics(y_pred, y_true, s_true, s_pred = None):\n",
    "    metrics = {}\n",
    "    # Get  overall accuracy\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    # Get accuracy by group\n",
    "    metrics['accuracy_sensitive'] = accuracy_score(y_true[s_true == 1], y_pred[s_true == 1])\n",
    "    metrics['accuracy_not_sensitive'] = accuracy_score(y_true[s_true == 0], y_pred[s_true == 0])\n",
    "\n",
    "    # # Get s accuracy overall and by group\n",
    "    if s_pred is not None:\n",
    "        # ***************where s problem is*************\n",
    "        metrics['s_accuracy'] = accuracy_score(s_true, s_pred)\n",
    "        metrics['s_accuracy_sensitive'] = accuracy_score(s_true[s_true == 1], s_pred[s_true == 1])\n",
    "        metrics['s_accuracy_not_sensitive'] = accuracy_score(s_true[s_true == 0], s_pred[s_true == 0])\n",
    "\n",
    "    # Get overall confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fpr = conf_matrix[0][1] / (conf_matrix[0][1] + conf_matrix[0][0])\n",
    "    fnr = conf_matrix[1][0] / (conf_matrix[1][0] + conf_matrix[1][1])\n",
    "    # Get confusion matrix for each s value\n",
    "    # Seperate y_pred and y_true by where s_true is 1 and 0\n",
    "    y_pred_sensitive = y_pred[s_true == 1]\n",
    "    y_true_sensitive = y_true[s_true == 1]\n",
    "    y_pred_not_sensitive = y_pred[s_true == 0]\n",
    "    y_true_not_sensitive = y_true[s_true == 0]\n",
    "    conf_matrix_sensitive = confusion_matrix(y_true_sensitive, y_pred_sensitive)\n",
    "    conf_matrix_not_sensitive = confusion_matrix(y_true_not_sensitive, y_pred_not_sensitive)\n",
    "    fpr_sensitive = conf_matrix_sensitive[0][1] / (conf_matrix_sensitive[0][1] + conf_matrix_sensitive[0][0])\n",
    "    fnr_sensitive = conf_matrix_sensitive[1][0] / (conf_matrix_sensitive[1][0] + conf_matrix_sensitive[1][1])\n",
    "    fpr_not_sensitive = conf_matrix_not_sensitive[0][1] / (conf_matrix_not_sensitive[0][1] + conf_matrix_not_sensitive[0][0])\n",
    "    fnr_not_sensitive = conf_matrix_not_sensitive[1][0] / (conf_matrix_not_sensitive[1][0] + conf_matrix_not_sensitive[1][1])\n",
    "\n",
    "    # Calculate positive rates\n",
    "\n",
    "    positive_rate_sensitive = (conf_matrix_sensitive[1][1] + conf_matrix_sensitive[0][1]) / len(y_true_sensitive)\n",
    "    positive_rate_not_sensitive = (conf_matrix_not_sensitive[1][1] + conf_matrix_not_sensitive[0][1]) / len(y_true_not_sensitive)\n",
    "    positive_rate = (conf_matrix[1][1] + conf_matrix[0][1]) / len(y_true)\n",
    "    true_pos_rate_not_sensitive = (conf_matrix_not_sensitive[1][1]+conf_matrix_not_sensitive[1][0]) / len(y_true_not_sensitive)\n",
    "    true_pos_rate_sensitive = (conf_matrix_sensitive[1][1]+conf_matrix_sensitive[1][0]) / len(y_true_sensitive)\n",
    "\n",
    "    # Add metrics to dict\n",
    "    metrics['fpr'] = fpr\n",
    "    metrics['fnr'] = fnr\n",
    "    metrics['fpr_sensitive'] = fpr_sensitive\n",
    "    metrics['fnr_sensitive'] = fnr_sensitive\n",
    "    metrics['fpr_not_sensitive'] = fpr_not_sensitive\n",
    "    metrics['fnr_not_sensitive'] = fnr_not_sensitive\n",
    "    metrics['positive_rate_sensitive'] = positive_rate_sensitive\n",
    "    metrics['positive_rate_not_sensitive'] = positive_rate_not_sensitive\n",
    "    metrics['positive_rate'] = positive_rate\n",
    "    metrics['true_pos_rate_sensitive'] = true_pos_rate_sensitive\n",
    "    metrics['true_pos_rate_not_sensitive'] = true_pos_rate_not_sensitive\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all of the metrics to one file for each dataset. Write to fairness_metrics folder\n",
    "def write_fairness(data_name, metrics_list):\n",
    "    file_path = './fairness_results/' + data_name\n",
    "        #file_name = data_name + '_fairness_metrics.txt'\n",
    "    with open(file_path, 'w') as f:\n",
    "        for metrics in metrics_list:\n",
    "            for metric in metrics.keys():\n",
    "                f.write(metric + ':' + str(metrics[metric]) + '\\n')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_by_name(data_name, accuracies):\n",
    "    args = get_args(data_name)\n",
    "    train_loader, test_loader = get_xsy_loaders(os.path.join(args.data_path, args.train_file_name),\n",
    "                                                    os.path.join(args.data_path, args.test_file_name),\n",
    "                                                    args.data_name, args.sensitive, args.batch_size_te, args)\n",
    "    metrics_list = []\n",
    "    for id in accuracies[data_name].keys():\n",
    "        y_pred = accuracies[data_name][id]['y_pred'][0]\n",
    "        y_true = accuracies[data_name][id]['y_true'][0]\n",
    "        s_true = test_loader.dataset.s\n",
    "        s_pred = accuracies[data_name][id]['s_pred'][0]\n",
    "        metrics = get_fairness_metrics(y_pred, y_true, s_true, s_pred=s_pred)\n",
    "        metrics_list.append(metrics)\n",
    "    return metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_metrics = get_fairness_by_name('adult', accuracies)\n",
    "adult_age_metrics = get_fairness_by_name('adult_age', accuracies)\n",
    "scf_metrics = get_fairness_by_name('SCF_Race', accuracies)\n",
    "scf_siblings_metrics = get_fairness_by_name('SCF_Siblings', accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_metrics(metrics_list):\n",
    "    avg_metrics = {}\n",
    "    for metric in metrics_list[0].keys():\n",
    "        avg_metrics[metric] = sum([metrics[metric] for metrics in metrics_list]) / len(metrics_list)\n",
    "    return avg_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_adult_metrics = average_metrics(adult_metrics)\n",
    "avg_adult_age_metrics = average_metrics(adult_age_metrics)\n",
    "avg_scf_metrics = average_metrics(scf_metrics)\n",
    "avg_scf_siblings_metrics = average_metrics(scf_siblings_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
